# ===----------------------------------------------------------------------=== #
#
# This file is Modular Inc proprietary.
#
# ===----------------------------------------------------------------------=== #
"""Audio generation interface definitions for Modular's MAX API.

This module provides data structures and interfaces for handling audio generation
responses, including status tracking and audio data encapsulation.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Optional, Union

import msgspec
import numpy as np
from max.interfaces.context import SamplingParams
from max.interfaces.request import Request
from max.interfaces.status import GenerationStatus


@dataclass(frozen=True)
class AudioGenerationRequest(Request):
    index: int
    """The sequence order of this request within a batch. This is useful for
    maintaining the order of requests when processing multiple requests
    simultaneously, ensuring that responses can be matched back to their
    corresponding requests accurately.
    """

    model: str
    """The name of the model to be used for generating audio chunks. This should match
    the available models on the server and determines the behavior and
    capabilities of the response generation.
    """

    lora: str | None = None
    """The name of the LoRA to be used for generating audio chunks. This should match
    the available models on the server and determines the behavior and
    capabilities of the response generation.
    """

    input: Optional[str] = None
    """The text to generate audio for. The maximum length is 4096 characters.
    """

    audio_prompt_tokens: list[int] = field(default_factory=list)
    """The prompt speech IDs to use for audio generation."""

    audio_prompt_transcription: str = ""
    """The audio prompt transcription to use for audio generation."""

    sampling_params: SamplingParams = SamplingParams()
    """Request sampling configuration options."""

    _assistant_message_override: str | None = None
    """(ONLY FOR BENCHMARKING PURPOSES) An assistant message that replaces the
    speech token pattern."""

    prompt: Optional[list[int] | str] = field(default=None)
    """Optionally provide a preprocessed list of token ids or a prompt string to pass as input directly into the model.
    This replaces automatically generating TokenGeneratorRequestMessages given the input, audio prompt tokens,
    audio prompt transcription fields."""

    streaming: bool = True
    """Whether to stream the audio generation."""

    buffer_speech_tokens: np.ndarray | None = None
    """An optional field potentially containing the last N speech tokens
    generated by the model from a previous request.

    When this field is specified, this tensor is used to buffer the tokens sent
    to the audio decoder.
    """

    def __post_init__(self) -> None:
        if self.prompt is None and self.input is None:
            raise RuntimeError("either token_ids or input must be provided.")


class AudioGenerationMetadata(
    msgspec.Struct, tag=True, omit_defaults=True, kw_only=True
):
    """
    Represents metadata associated with audio generation.

    This class will eventually replace the metadata dictionary used throughout
    the AudioGenerationOutput object, providing a structured and type-safe
    alternative for audio generation metadata.

    Configuration:
        sample_rate: The sample rate of the generated audio in Hz.
        duration: The duration of the generated audio in seconds.
        chunk_id: Identifier for the audio chunk (useful for streaming).
        timestamp: Timestamp when the audio was generated.
        final_chunk: Whether this is the final chunk in a streaming sequence.
        model_name: Name of the model used for generation.
        request_id: Unique identifier for the generation request.
        tokens_generated: Number of tokens generated for this audio.
        processing_time: Time taken to process this audio chunk in seconds.
        echo: Echo of the input prompt or identifier for verification.
    """

    sample_rate: Optional[int] = None
    duration: Optional[float] = None
    chunk_id: Optional[int] = None
    timestamp: Optional[str] = None
    final_chunk: Optional[bool] = None
    model_name: Optional[str] = None
    request_id: Optional[str] = None
    tokens_generated: Optional[int] = None
    processing_time: Optional[float] = None
    echo: Optional[str] = None

    def to_dict(self) -> dict[str, Union[int, float, str, bool]]:
        """
        Convert the metadata to a dictionary format.

        Returns:
            dict[str, any]: Dictionary representation of the metadata.
        """
        result = {}
        for attr in self.__annotations__:
            if value := getattr(self, attr, None):
                result[attr] = value
        return result

    def __eq__(self, other: Any) -> bool:
        """
        Support equality comparison with both AudioGenerationMetadata objects and dictionaries.

        This allows tests to compare metadata objects with plain dictionaries.
        """
        if isinstance(other, AudioGenerationMetadata):
            return super().__eq__(other)
        elif isinstance(other, dict):
            return self.to_dict() == other
        return False


class AudioGenerationResponse(msgspec.Struct, tag=True, omit_defaults=True):
    """Represents a response from the audio generation API.

    This class encapsulates the result of an audio generation request, including
    the final status, generated audio data, and optional buffered speech tokens.
    """

    final_status: GenerationStatus
    """The final status of the generation process."""
    audio: Optional[np.ndarray] = None
    """The generated audio data, if available."""
    buffer_speech_tokens: Optional[np.ndarray] = None
    """Buffered speech tokens, if available."""

    @property
    def is_done(self) -> bool:
        """Indicates whether the audio generation process is complete.

        Returns:
            :class:`bool`: ``True`` if generation is done, ``False`` otherwise.
        """
        return self.final_status.is_done

    @property
    def has_audio_data(self) -> bool:
        """Checks if audio data is present in the response.

        Returns:
            :class:`bool`: ``True`` if audio data is available, ``False`` otherwise.
        """
        return self.audio is not None

    @property
    def audio_data(self) -> np.ndarray:
        """Returns the audio data if available.

        Returns:
            :class:`np.ndarray`: The generated audio data.

        Raises:
            :class:`AssertionError`: If audio data is not available.
        """
        assert self.audio is not None
        return self.audio


class AudioGeneratorOutput(msgspec.Struct, tag=True, omit_defaults=True):
    """
    Represents the output of an audio generation step.
    """

    audio_data: np.ndarray
    """The generated audio data as a NumPy array."""

    metadata: AudioGenerationMetadata
    """Metadata associated with the audio generation, such as chunk information, prompt details, or other relevant context."""

    is_done: bool
    """Indicates whether the audio generation is complete (True) or if more chunks are expected (False)."""

    buffer_speech_tokens: np.ndarray | None = None
    """An optional field containing the last N speech tokens generated by the model. This can be used to buffer speech tokens for a follow-up request, enabling seamless continuation of audio generation."""
